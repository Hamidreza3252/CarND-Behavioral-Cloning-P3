{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavorial Cloning  \n",
    "\n",
    "### Review Articles\n",
    "- [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html#adam)\n",
    "\n",
    "### Enrichment Readings \n",
    "- [Review: SegNet (Semantic Segmentation)](https://towardsdatascience.com/review-segnet-semantic-segmentation-e66f2e30fb96)\n",
    "- [Installing TensorFlow Object Detection API on Windows 10](https://medium.com/@marklabinski/installing-tensorflow-object-detection-api-on-windows-10-7a4eb83e1e7b)\n",
    "- [Multi-Sensor Data Fusion (MSDF) for Driverless Cars, An Essential Primer\n",
    "](https://medium.com/@lance.eliot/multi-sensor-data-fusion-msdf-for-driverless-cars-an-essential-primer-a1948bb8b57c)\n",
    "- [How to validate your deep learning model with the Diffgram SDK — Tutorial](https://medium.com/diffgram/how-to-validate-your-deep-learning-model-with-the-diffgram-sdk-tutorial-22234a9a35?_hsenc=p2ANqtz-_o0BTtZu_UHjEOD4taLJqxrDs0xDP_xl-Do12O-pIoMFjzmoS945j4gYYqt96YCTANNiUtfOuRCPnutqNDwwtgSCRMhQ&_hsmi=74444548)\n",
    "- [How do I design a visual deep learning system in 2019?](https://medium.com/diffgram/how-do-i-design-a-visual-deep-learning-system-in-2019-8597aaa35d03?_hsenc=p2ANqtz-_o0BTtZu_UHjEOD4taLJqxrDs0xDP_xl-Do12O-pIoMFjzmoS945j4gYYqt96YCTANNiUtfOuRCPnutqNDwwtgSCRMhQ&_hsmi=74444548)\n",
    "\n",
    "### Useful Tips\n",
    "- [A detailed example of how to use data generators with Keras](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)\n",
    "- [Writing Custom Keras Generators](https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a)\n",
    "\n",
    "### Image Database\n",
    "- [A dataset of images containing...](https://www.kaggle.com/moltean/fruits/downloads/fruits.zip/57)\n",
    "\n",
    "### General Tips\n",
    "- It is not necessary to use the left and right images to derive a successful model. Recording recovery driving from the sides of the road is also effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Center Driving**\n",
    "\n",
    "So that the car drives down the center of the road, it's essential to capture center lane driving. Try driving around the track various times while staying as close to the middle of the track as possible even when making turns.\n",
    "\n",
    "In the real world, the car would need to stay in a lane rather than driving down the center. But for the purposes of this project, aim for center of the road driving.\n",
    "\n",
    "**Strategies for Collecting Data**\n",
    "\n",
    "Now that you have driven the simulator and know how to record data, it's time to think about collecting data that will ensure a successful model. There are a few general concepts to think about that we will later discuss in more detail:\n",
    "\n",
    "- the car should stay in the center of the road as much as possible\n",
    "- if the car veers off to the side, it should recover back to center\n",
    "- driving counter-clockwise can help the model generalize\n",
    "- flipping the images is a quick way to augment the data\n",
    "- collecting data from the second track can also help generalize the model\n",
    "- we want to avoid overfitting or underfitting when training the model\n",
    "- knowing when to stop collecting more data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from random import shuffle\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "\n",
    "from keras.layers import Input, InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, Lambda, Cropping2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import selfDrivingCarModules\n",
    "reload(selfDrivingCarModules)\n",
    "from selfDrivingCarModules import Sdc\n",
    "\n",
    "import dataProcessingModules\n",
    "reload(dataProcessingModules)\n",
    "from dataProcessingModules import DataGenerator4Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up hyper-parameters for data generation modules  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/Lake-Track/\"\n",
    "csv_file = data_path + \"sim-00/driving_log.csv\"\n",
    "# csv_file = data_path + \"driving_log-combined.csv\"\n",
    "\n",
    "data_path = \"data/\"\n",
    "csv_file = data_path + \"driving_log-combined.csv\"\n",
    "\n",
    "x_partitions = {\"train\": None, \"validation\": None}\n",
    "# y_partitions = {\"train\": None, \"validation\": None}\n",
    "\n",
    "batch_size = 64\n",
    "image_sizes = (160, 320)\n",
    "\n",
    "params = {\"dims\": (*image_sizes, 3), \n",
    "          \"batch_size\": batch_size, \n",
    "          \"n_channels\": 1,\n",
    "          \"augment_data\": True,\n",
    "          \"rescale_zero_mean\": True,\n",
    "          \"shuffle\": True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and validation data generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size=64 , number of batches=1373\n",
      "sample training y_data: 0.426, -0.426\n",
      "sample validation y_data: -0.100, 0.100\n",
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# x_partitions[\"train\"], x_partitions[\"validation\"], y_partitions[\"train\"], y_partitions[\"validation\"] = \\\n",
    "#     Sdc.generate_partition_ids(data_path, csv_file, validation_split=0.2, limit=64, image_series_type=Sdc.__CENTER_IMAGES__)\n",
    "\n",
    "x_partitions[\"train\"], x_partitions[\"validation\"], y_values = \\\n",
    "    Sdc.generate_partition_ids(data_path, csv_file, validation_split=0.2, limit=0, image_series_type=Sdc.__ALL_IMAGES__, \n",
    "                              correction_factor=0.1)\n",
    "\n",
    "training_generator = DataGenerator4Regression(x_partitions[\"train\"], y_values, **params)\n",
    "validation_generator = DataGenerator4Regression(x_partitions[\"validation\"], y_values, **params)\n",
    "\n",
    "# testing data generators \n",
    "x_data = training_generator[0][0]\n",
    "y_data = training_generator[0][1]\n",
    "\n",
    "test_index = 10\n",
    "\n",
    "print(\"batch size={0:d} , number of batches={1:d}\".format(batch_size, len(training_generator)))\n",
    "\n",
    "# for augmented, they should be opposite values\n",
    "print(\"sample training y_data: {0:0.3f}, {1:0.3f}\".format(y_data[test_index], y_data[test_index + batch_size]))\n",
    "\n",
    "y_data = validation_generator[0][1]\n",
    "print(\"sample validation y_data: {0:0.3f}, {1:0.3f}\".format(y_data[test_index], y_data[test_index + batch_size]))\n",
    "\n",
    "# a check-point whether the values are re-scaled or not\n",
    "print(np.min(x_data[test_index]), np.max(x_data[test_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training New CNN Model from Scratch (No Transfer Learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_2 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer_01 (Conv2D)       (None, 90, 320, 16)       1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 90, 320, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 90, 320, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pool_01 (MaxPooling2D)   (None, 45, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv_layer_02 (Conv2D)       (None, 45, 160, 32)       4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 45, 160, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 45, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)    (None, 22, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer_03 (Conv2D)       (None, 22, 80, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 22, 80, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool_3 (MaxPooling2D)    (None, 11, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer_04 (Conv2D)       (None, 11, 40, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 11, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 11, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool_4 (MaxPooling2D)    (None, 5, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv_layer_05 (Conv2D)       (None, 5, 20, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5, 20, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pool_5 (MaxPooling2D)    (None, 2, 10, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv_layer_06 (Conv2D)       (None, 2, 10, 128)        8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 10, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 10, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pool_6 (MaxPooling2D)    (None, 1, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 172,609\n",
      "Trainable params: 171,937\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sdc.generate_model(\"cnn-01\", image_sizes, rescale_input_zero_mean=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"001-model-conv-6-fc-4-all-aug-crop\"\n",
    "model_filename = \"saved-models/\" + model_name + \".h5\"\n",
    "history_filename = \"saved-models/\" + model_name + \".p\"\n",
    "\n",
    "checkpoint_file = model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "  4/435 [..............................] - ETA: 50:06 - loss: 80.2208  "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=checkpoint_file, monitor=\"val_loss\", save_best_only=True)\n",
    "stopper = EarlyStopping(monitor=\"val_loss\", min_delta=1e-5, patience=5)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit_generator(generator=training_generator, validation_data=validation_generator, \n",
    "                              use_multiprocessing=True, workers=2, epochs=50, callbacks=[checkpoint, stopper])\n",
    "\n",
    "model.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d2a6ebf6a723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "with open(history_filename, \"wb\") as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Model (InceptionV3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our images first, and we'll check what we have\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import Input, Lambda\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "resized_input_shape = (139, 139)\n",
    "\n",
    "freeze_flag = False # `True` to freeze layers, `False` for full training \n",
    "weights_flag = \"imagenet\" # 'imagenet' or None \n",
    "preprocess_flag = True # Should be true for ImageNet pre-trained typically \n",
    "\n",
    "\n",
    "# Using smaller than the default 299x299x3 input for InceptionV3\n",
    "# which will speed up training. Keras v2.0.9 supports down to 139x139x3\n",
    "\n",
    "# input_size = 139\n",
    "\n",
    "# Using Inception with ImageNet pre-trained weights\n",
    "inception = InceptionV3(weights=weights_flag, include_top=False, input_shape=(*resized_input_shape, 3))\n",
    "\n",
    "if (freeze_flag == True):\n",
    "    for layer in inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "# inception.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Makes the input placeholder layer with image shape\n",
    "input_ph = Input(shape=(*image_sizes, 3))\n",
    "\n",
    "preprocessed_input = Cropping2D(cropping=((50,20), (0,0)), input_shape=(*image_sizes, 3))(input_ph)\n",
    "preprocessed_input = Lambda(lambda image: tf.image.resize_images( \\\n",
    "    image, (139, 139), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False))(preprocessed_input)\n",
    "\n",
    "# preprocessed_input = Lambda(lambda x: x / 255.0 - 0.5, input_shape=(*input_size, 3))(preprocessed_input)\n",
    "\n",
    "inception_output = inception(preprocessed_input)\n",
    "\n",
    "# layer_output = Flatten()(inception_output)\n",
    "layer_output = GlobalAveragePooling2D()(inception_output)\n",
    "\n",
    "layer_output = Dense(128, activation=None, name=\"fc1\")(layer_output)\n",
    "layer_output = Dropout(rate=0.20)(layer_output)\n",
    "\n",
    "layer_output = Dense(64, activation=None, name=\"fc2\")(layer_output)\n",
    "layer_output = Dropout(rate=0.20)(layer_output)\n",
    "\n",
    "layer_output = Dense(32, activation=None, name=\"fc3\")(layer_output)\n",
    "layer_output = Dropout(rate=0.20)(layer_output)\n",
    "\n",
    "predictions = Dense(1, activation=None, name=\"fc4\")(layer_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 139, 139, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,075,425\n",
      "Trainable params: 22,040,993\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_ph, outputs=predictions, name=\"cnn-20\")\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"051-model-inception-partial-data-04\"\n",
    "model_filename = \"saved-models/\" + model_name + \".h5\"\n",
    "history_filename = \"saved-models/\" + model_name + \".p\"\n",
    "\n",
    "checkpoint_file = model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=checkpoint_file, monitor=\"val_loss\", save_best_only=True)\n",
    "stopper = EarlyStopping(monitor=\"val_loss\", min_delta=1e-6, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1373/1373 [==============================] - 14845s 11s/step - loss: 0.2104 - mean_squared_error: 0.2104 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/100\n",
      "1373/1373 [==============================] - 14788s 11s/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
      "Epoch 3/100\n",
      "1373/1373 [==============================] - 22335s 16s/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 4/100\n",
      "1373/1373 [==============================] - 14916s 11s/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 5/100\n",
      "1373/1373 [==============================] - 15023s 11s/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
      "Epoch 6/100\n",
      "1373/1373 [==============================] - 15071s 11s/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 7/100\n",
      "1373/1373 [==============================] - 15078s 11s/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
      "Epoch 8/100\n",
      "1373/1373 [==============================] - 15408s 11s/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 9/100\n",
      "  12/1373 [..............................] - ETA: 4:19:06 - loss: 0.0102 - mean_squared_error: 0.0102"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=training_generator, validation_data=validation_generator, \n",
    "                              use_multiprocessing=True, workers=2, epochs=100, callbacks=[checkpoint])\n",
    "\n",
    "model.save(model_filename)\n",
    "\n",
    "with open(history_filename, \"wb\") as file_pi:\n",
    "    pickle.dump(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
